{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO02JGsjAdkfpey/Ie9/5SM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishwaryasharmaccoew/CIS6930-NLP/blob/aishwarya/Gensim_LSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "otqa5n7rlPRT"
      },
      "outputs": [],
      "source": [
        "from gensim import models\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LsiModel\n",
        "from nltk.corpus import stopwords\n",
        "from gensim import corpora\n",
        "import warnings\n",
        "import pandas as pd\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#load pre-processed data\n",
        "url= \"/content/sample_data/depression_post_features_tfidf_256_clean.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "#remove words have letters less than 5\n",
        "df['post'] = df['post'].fillna('').apply(lambda x: ' '.join([w for w in x.split() if len(w)>5]))\n",
        "\n",
        "# tokenization\n",
        "tokenized_doc = df['post'].fillna('').apply(lambda x: x.split())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_topics=10\n",
        "#Apply LSA\n",
        "data_processed = [[word for word in document ] for document in tokenized_doc]\n",
        "\n",
        "# Create a dictionary from the preprocessed dataset\n",
        "dictionary = Dictionary(data_processed)\n",
        "\n",
        "# Convert the dictionary into a bag-of-words corpus\n",
        "corpus = [dictionary.doc2bow(text) for text in data_processed]\n",
        "\n",
        "# Train the LSA model with 5 topics\n",
        "lsa_model = LsiModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
        "\n",
        "# Show topics\n",
        "topics = lsa_model.show_topics(num_topics=num_topics, num_words=5, formatted=False)\n",
        "topic_strings = [', '.join([word[0] for word in topic[1]]) for topic in topics]\n",
        "\n",
        "# Print the topic strings\n",
        "tnum=0\n",
        "for topic_string in topic_strings:\n",
        "    tnum=tnum+1\n",
        "    print(\"Topic\",tnum,\": \",topic_string)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkGJbW-ilX9B",
        "outputId": "dd56de57-6ae8-433c-a033-8bdb4d33597c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1 :  friend, people, really, depression, always\n",
            "Topic 2 :  friend, depression, school, feeling, better\n",
            "Topic 3 :  people, really, friend, depression, school\n",
            "Topic 4 :  really, depression, friend, anxiety, anything\n",
            "Topic 5 :  really, fucking, depression, people, everything\n",
            "Topic 6 :  school, feeling, friend, parent, someone\n",
            "Topic 7 :  fucking, feeling, always, depression, thought\n",
            "Topic 8 :  feeling, fucking, always, school, anything\n",
            "Topic 9 :  always, anything, anymore, fucking, nothing\n",
            "Topic 10 :  better, thought, feeling, always, anything\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the coherence scores\n",
        "cv_coherence_model = CoherenceModel(model=lsa_model, corpus=corpus,\n",
        "                                    coherence='c_v', texts=data_processed)\n",
        "cv_coherence = cv_coherence_model.get_coherence()\n",
        "print(\"C_V Coherence Score:\", cv_coherence)\n",
        "\n",
        "umass_coherence_model = CoherenceModel(model=lsa_model, corpus=corpus,\n",
        "                                       coherence='u_mass')\n",
        "umass_coherence = umass_coherence_model.get_coherence()\n",
        "print(\"U_mass Coherence Score:\", umass_coherence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkgXAqE3lq_F",
        "outputId": "462a38d1-d391-47ae-fcc0-cb42dd8c5263"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C_V Coherence Score: 0.4438596489128037\n",
            "U_mass Coherence Score: -2.111011644417176\n"
          ]
        }
      ]
    }
  ]
}